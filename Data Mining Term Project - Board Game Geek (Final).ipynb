{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Term Project - Board Game Geek Rating Prediction/Experimentations\n",
    "# Student: Kaite (Kurt) Li\n",
    "# ID: 100 164 5704\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intention of my Post\n",
    "## The intention of this post if to illustrate the term project of my Data Mining class. First and foremost, since preproecessing is a huge and necessary part of data mining, this post show step by step on how the preprocessing is done. Also at the end the preprocessing, a breif summary will be provided for the readers to remind what we have accomplished upon till that point. Secondly, a quick data analysis will be provided to see how the data look like after all the preprocessing work, this part gathers good intelligence of the data which we will be working with for the rest of the post. Thirdly, the prediction of the rating based on text comments is awefully similar to our third assignment which we are predicting movie reviews based on text reviews; however, the difference is that the ratings of the board games are continuous numbers from 0 to 10. I am planning on discretizing these ratings so that there are only 11 class labels (0 through 10). After that, I will use sklearn's Multinomial Naive Bayes classifiers to experiment with the data set and gather all the accuracies. My contribution would be implementing ensemble voting, analyze my mechanism, introducing different measurements. Fourthly, I will finalize a ensemble classfier to predict input reviews from outside. Lastly, readers should also read \"Important Note\" which reveals critical information throughout the post if reader wants to try running the notebook himself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note: \n",
    "#### Please be patient when you run this notebook, because even after making this notebook as concise as I can, the running time is still very long as we are dealing with multiple classifiers using ensemble over a 2.7 million row data set. Thank you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "## 1. AnywherePython Flask Webapp Deployment with Serialized Classfier: \n",
    "http://kaiteli14.pythonanywhere.com\n",
    "   \n",
    "## 2. Github Repo Link (Timestamps): \n",
    "https://github.com/kaiteli14/DataMiningTermProject\n",
    "\n",
    "## 3. Video Demo:\n",
    "https://www.youtube.com/watch?v=z9A6rye8Elw&feature=youtu.be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "# !pip install Unidecode\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import re\n",
    "import unidecode\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB as NB\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# We are loading all data sets here just in case we need them, but the most important one we are going to be working on is \"review_data\"/\n",
    "# game_df = pd.read_csv(\"boardgamegeek-reviews/2019-05-02.csv\")\n",
    "review_df = pd.read_csv(\"boardgamegeek-reviews/bgg-13m-reviews.csv\")\n",
    "# game_detail_df = pd.read_csv(\"boardgamegeek-reviews/games_detailed_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Drop rows that has no comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sidehacker</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Varthlokkur</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dougthonus</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Currently, this sits on my list as my favorite...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cypar7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I know it says how many plays, but many, many ...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ssmooth</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         user  rating  \\\n",
       "0           0   sidehacker    10.0   \n",
       "1           1  Varthlokkur    10.0   \n",
       "2           2   dougthonus    10.0   \n",
       "3           3       cypar7    10.0   \n",
       "4           4      ssmooth    10.0   \n",
       "\n",
       "                                             comment  ID   name  \n",
       "0                                                NaN  13  Catan  \n",
       "1                                                NaN  13  Catan  \n",
       "2  Currently, this sits on my list as my favorite...  13  Catan  \n",
       "3  I know it says how many plays, but many, many ...  13  Catan  \n",
       "4                                                NaN  13  Catan  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at how the data look like before the drop.\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13170073, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the shape of the data before the drop.\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop all the rows that has \"NaN\" in the \"comment\".\n",
    "review_df.dropna(subset=[\"comment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dougthonus</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Currently, this sits on my list as my favorite...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cypar7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I know it says how many plays, but many, many ...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>hreimer</td>\n",
       "      <td>10.0</td>\n",
       "      <td>i will never tire of this game.. Awesome</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>daredevil</td>\n",
       "      <td>10.0</td>\n",
       "      <td>This is probably the best game I ever played. ...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>hurkle</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Fantastic game. Got me hooked on games all ove...</td>\n",
       "      <td>13</td>\n",
       "      <td>Catan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        user  rating  \\\n",
       "2            2  dougthonus    10.0   \n",
       "3            3      cypar7    10.0   \n",
       "7            7     hreimer    10.0   \n",
       "11          11   daredevil    10.0   \n",
       "16          16      hurkle    10.0   \n",
       "\n",
       "                                              comment  ID   name  \n",
       "2   Currently, this sits on my list as my favorite...  13  Catan  \n",
       "3   I know it says how many plays, but many, many ...  13  Catan  \n",
       "7            i will never tire of this game.. Awesome  13  Catan  \n",
       "11  This is probably the best game I ever played. ...  13  Catan  \n",
       "16  Fantastic game. Got me hooked on games all ove...  13  Catan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at how the data look like after the drop.\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2637756, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the shape after the drop.\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Transform comment into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df[\"comment\"] = review_df[\"comment\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for punctuation removal, similar to the one in my practice kaggle notebook.\n",
    "def functuation_removal(comment):\n",
    "    return comment.translate(comment.maketrans('','', string.punctuation))\n",
    "\n",
    "review_df[\"comment\"] = review_df[\"comment\"].apply(lambda comment:functuation_removal(comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Remove url, html, and acceted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miscellaneous_removal(comment):\n",
    "    pattern_html = re.compile(r'<.*?>')\n",
    "    pattern_url = re.compile(r'https?://\\S+\\www\\.\\S+')\n",
    "    comment = pattern_html.sub(r'', comment)\n",
    "    comment = pattern_url.sub(r'', comment)\n",
    "    comment = unidecode.unidecode(comment)\n",
    "    return comment\n",
    "\n",
    "review_df[\"comment\"] = review_df[\"comment\"].apply(lambda comment: miscellaneous_removal(comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stop_words_removal(comment):\n",
    "    return \" \".join([word for word in tokenizer.tokenize(comment) if word not in stop_words])\n",
    "\n",
    "review_df[\"comment\"] = review_df[\"comment\"].apply(stop_words_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Step: Remove Non English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def remove_non_english_words(comment):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(comment) if w.lower() in words or not w.isalpha())\n",
    "\n",
    "review_df[\"comment\"] = review_df[\"comment\"].apply(remove_non_english_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Rounding all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works as discretization.\n",
    "review_df[\"rating\"] = review_df[\"rating\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are using rating and comment columns to build the prediction model, therefore, we should remove the unnecesarry columns that we do not need.\n",
    "review_df.drop(review_df.columns[0], axis=1, inplace=True) # This removes the original index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop(review_df.columns[3], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop(review_df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop(review_df.columns[2], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>currently list favorite game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>know many many many uncounted version best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>never tire game awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>probably best game ever thinking negotiation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>fantastic game got hooked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating                                       comment\n",
       "2       10                  currently list favorite game\n",
       "3       10    know many many many uncounted version best\n",
       "7       10                       never tire game awesome\n",
       "11      10  probably best game ever thinking negotiation\n",
       "16      10                     fantastic game got hooked"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Shuffling rows of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Splitting data set into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming DataFrame to Numpy\n",
    "review_np = review_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporant Note: Because the size of the data is to large, when I run SVM classifier, the Kaggle Notebook didn't finish for more than an hour; therefore I have to comment out the original \"x\" and \"y\" and take a subset of them. Please be aware of this if you want to run it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"x\" is the comment column of the data and \"y\" is the rating column of the data\n",
    "x = review_np[:, 1:]\n",
    "y = review_np[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let us use skilearn function call to split the data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "The shape of the x_train:  (2110204, 1)\n",
      "The shape of the y_train:  (2110204, 1)\n",
      "-------------------------------------------\n",
      "The shape of the x_test:  (527552, 1)\n",
      "The shape of the y_test:  (527552, 1)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's look the shape of the data for \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The shape of the x_train: \", x_train.shape)\n",
    "print(\"The shape of the y_train: \",y_train.shape)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The shape of the x_test: \", x_test.shape)\n",
    "print(\"The shape of the y_test: \",y_test.shape)\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is partition of roughly 5% or first 100,000 rows of data to fit our first Naive Bay Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us try 30% of the original data size and add more later if it is needed. \n",
    "# Original shape of x_train, y_train is (2110204, 1) and original shape of x_test, y_test is (527552, 1)\n",
    "\n",
    "x_train_0, y_train_0 = x_train[:100000, :], y_train[:100000, :]\n",
    "x_test, y_test = x_test[:150000, :], y_test[:150000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following are another two partition are also roughly 5% of the total data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1 = x_train[100000:200000, :], y_train[100000:200000, :]\n",
    "x_train_2, y_train_2 = x_train[200000:300000, :], y_train[200000:300000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "The shape of the x_train:  (2110204, 1)\n",
      "The shape of the y_train:  (2110204, 1)\n",
      "-------------------------------------------\n",
      "The shape of the x_test:  (150000, 1)\n",
      "The shape of the y_test:  (150000, 1)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's look the shape of the data for \n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The shape of the x_train: \", x_train.shape)\n",
    "print(\"The shape of the y_train: \",y_train.shape)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The shape of the x_test: \", x_test.shape)\n",
    "print(\"The shape of the y_test: \",y_test.shape)\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_0, x_test, y_train_0, y_test = pd.DataFrame(data=x_train_0, columns=[\"comment\"]), pd.DataFrame(data=x_test, columns=[\"comment\"]),\\\n",
    "pd.DataFrame(data=y_train_0, columns=[\"rating\"]), pd.DataFrame(data=y_test, columns=[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, y_train_1 = pd.DataFrame(data=x_train_1, columns=[\"comment\"]), pd.DataFrame(data=y_train_1, columns=[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2, y_train_2 = pd.DataFrame(data=x_train_2, columns=[\"comment\"]), pd.DataFrame(data=y_train_2, columns=[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breif Summary at this Point\n",
    "Understanding a data scientist's job is more than 60% of data preprocessing and also due to the fact that this data set is quite sizable, I have done the following preprocessing steps up on till this point:\n",
    "\n",
    "1. Remove rows that have no comment, the reason for this is because if the comment is blank, there is nothing we can work with as far as building a predictor is concerned; hence, a removal would be reasonable.\n",
    "2. Make all comment lower case because this way we won't classify same word into different categories.\n",
    "3. Punctuations have been removed.\n",
    "4. Urls, htmls, and accented characters are also removed to make the data even cleaner.\n",
    "5. Remove all the English stop words.\n",
    "6. Round all rating from 1 to 10, this is a better way to fit these rating to classfiers while maintain the correct meaning.\n",
    "7. Remove unnecessary columns.\n",
    "8. Shuffling all the rows of our data to make it even more natural before analysis and classification.\n",
    "9. Splitting data into 80% for traning and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis: View the data after the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>works reasonably well clone less 30 game reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>one easy learn lot strategic depth great varie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>cup tea best tend enjoy cutthroat still right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>find bit taste didnt see anything sway ill try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>fun auction game unfortunately oddly title off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>got 20 one feel little got lot replay value sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>well still risk still major real strategy begi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>game lot two player variant quite good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>tentative rating two terrible first impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>like different pewter silver gold associated d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>game mess really work theres good game think h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>finally theme close someone generation spectac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>complex version grid 4 4 light dark hollow sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>great elegant tactical game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>change lighter category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>simple nice game random random could memorize ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>abstract card game nominal theme play order wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>fun complicated lots significant luck componen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating                                            comment\n",
       "0        5  works reasonably well clone less 30 game reall...\n",
       "1        9  one easy learn lot strategic depth great varie...\n",
       "2        8  cup tea best tend enjoy cutthroat still right ...\n",
       "3        4  find bit taste didnt see anything sway ill try...\n",
       "4        7  fun auction game unfortunately oddly title off...\n",
       "5        9  got 20 one feel little got lot replay value sc...\n",
       "6        8  well still risk still major real strategy begi...\n",
       "7        8             game lot two player variant quite good\n",
       "8        4  tentative rating two terrible first impression...\n",
       "9        8  like different pewter silver gold associated d...\n",
       "10       4  game mess really work theres good game think h...\n",
       "11       9  finally theme close someone generation spectac...\n",
       "12       4  complex version grid 4 4 light dark hollow sol...\n",
       "13       8                        great elegant tactical game\n",
       "14       8                            change lighter category\n",
       "15       7  simple nice game random random could memorize ...\n",
       "16       7                                               late\n",
       "17       4  abstract card game nominal theme play order wi...\n",
       "18       9                                                   \n",
       "19       7  fun complicated lots significant luck componen..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look at the head of our data set now.\n",
    "review_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2637756, 2)\n"
     ]
    }
   ],
   "source": [
    "# Let us look at the shape of the data at this point.\n",
    "print(review_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis: Rating counts after decretization (0 through 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>217766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>526481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>574586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>657581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>239410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>153530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment\n",
       "rating         \n",
       "0            11\n",
       "1         20086\n",
       "2         40766\n",
       "3         70974\n",
       "4        136565\n",
       "5        217766\n",
       "6        526481\n",
       "7        574586\n",
       "8        657581\n",
       "9        239410\n",
       "10       153530"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following is a rating count from 0 to 10 after making everything discrete.\n",
    "review_df.groupby([\"rating\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis: Rating distribution visualized through histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Counts')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for the distribtuion of the rating across 1 to 10.\n",
    "plt = review_df['rating'].plot.hist()\n",
    "plt.set_xlabel(\"Rating from 0 to 10\")\n",
    "plt.set_ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models - Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vector = vectorizer.fit_transform(x_train_0[\"comment\"])\n",
    "test_vector = vectorizer.transform(x_test[\"comment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models - Naive Bayes Classifiers\n",
    "### The purpose of this section is to analyze the accuracies of sklearn Multinomial Naive Bayes classifier on our data in numerous ways. The reason I decided to use Naive Bayes classifiers instead of any other classifiers is that rating prediction based on text comment reviews are extremely similar to classification of positive/negative comments based on text comments (I have made my own Naive Bayes model in Assignment 3 which you can see that on my homepage). Since I have preprocessed my data into discrete format (0-10), we can think about the prediction as classification of the data into 11 classes intead of just 2. What I want to achieve and contribute after this section is to use ensemble method to improve accuracy which I learned from this course. I think it is good to try applying in class theory into practice. Furthermore, the entire data has been partitioned into 3 sectors of 33% each for the classifiers. The reason the proportion is decided this way is because this porportion will have accuracy around 31.5% which is very close to the accuracy of 32.6% when we use the entire 2.7 million rows of data. If we cut the data into even smaller pieces,then the accuracy will significantly drops. The whole point is to increase accuracy and we have to very careful when it comes to splitting data for ensemble method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Naive Bayes Classfier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using MultinomialNB here to check accuracy.\n",
    "Naive_Bayes_Multinomial = NB()\n",
    "target_train_vector = np.asarray(y_train_0[\"rating\"], dtype=\"|S6\")\n",
    "Naive_Bayes_Multinomial.fit(train_vector, target_train_vector)\n",
    "pred = Naive_Bayes_Multinomial.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the first Naive Bayes classifier trained over the FIRST 10% of the data is  29.66 %\n"
     ]
    }
   ],
   "source": [
    "# If we use the whole 2.7 million rows of data, then the accuracy result is around 30%; however if we use 30% of the whole data, we can still\n",
    "# achieve an accuraccy of 30% which is not too shaby at all. This is a good thing about Naive Byes With this, we can shorten the run time of all the experiments and also the restart\n",
    "# needs during the consturction of this notebook by substantial amount.\n",
    "target_test_vector = np.asarray(y_test[\"rating\"],dtype=\"|S6\")\n",
    "acc = accuracy_score(target_test_vector,pred)\n",
    "print(\"The accuracy for the first Naive Bayes classifier trained over the FIRST 10% of the data is \",\"{:.2f}\".format(acc * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Naive Bayes Classfier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_1 = feature_extraction.text.CountVectorizer()\n",
    "train_vector_1 = vectorizer_1.fit_transform(x_train_1[\"comment\"])\n",
    "test_vector_1 = vectorizer_1.transform(x_test[\"comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive_Bayes_Multinomial_1 = NB()\n",
    "target_train_vector_1 = np.asarray(y_train_1[\"rating\"], dtype=\"|S6\")\n",
    "Naive_Bayes_Multinomial_1.fit(train_vector_1, target_train_vector_1)\n",
    "pred_1 = Naive_Bayes_Multinomial_1.predict(test_vector_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the first Naive Bayes classifier trained over the SECOND 10% of the data is  29.71 %\n"
     ]
    }
   ],
   "source": [
    "target_test_vector_1 = np.asarray(y_test[\"rating\"],dtype=\"|S6\")\n",
    "acc_1 = accuracy_score(target_test_vector_1,pred_1)\n",
    "print(\"The accuracy for the first Naive Bayes classifier trained over the SECOND 10% of the data is \",\"{:.2f}\".format(acc_1 * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Naive Bayes Classfier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_2 = feature_extraction.text.CountVectorizer()\n",
    "train_vector_2 = vectorizer_2.fit_transform(x_train_2[\"comment\"])\n",
    "test_vector_2 = vectorizer_2.transform(x_test[\"comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive_Bayes_Multinomial_2 = NB()\n",
    "target_train_vector_2 = np.asarray(y_train_2[\"rating\"], dtype=\"|S6\")\n",
    "Naive_Bayes_Multinomial_2.fit(train_vector_2, target_train_vector_2)\n",
    "pred_2 = Naive_Bayes_Multinomial_2.predict(test_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the first Naive Bayes classifier trained over the LAST 10% of the data is  29.41 %\n"
     ]
    }
   ],
   "source": [
    "target_test_vector_2 = np.asarray(y_test[\"rating\"],dtype=\"|S6\")\n",
    "acc_2 = accuracy_score(target_test_vector_2,pred_2)\n",
    "print(\"The accuracy for the first Naive Bayes classifier trained over the LAST 10% of the data is \",\"{:.2f}\".format(acc_2 * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution - Building my own Ensemble Voting to Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, let's look at all the rows that our 3 classifiers have different prediciton and also the correct prediction from our y_test. The reason for this is because if all 3 classfiers have the same predictions, it does not matter if the prediction is right or wrong that any ensemble voting on 3 identical predictions will still be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row  0 , classfier ONE prediction:  7 , classfier TWO prediction:  7 , classfier THREE prediction:  6 , correct class is:  7\n",
      "row  1 , classfier ONE prediction:  8 , classfier TWO prediction:  7 , classfier THREE prediction:  8 , correct class is:  7\n",
      "row  2 , classfier ONE prediction:  6 , classfier TWO prediction:  5 , classfier THREE prediction:  6 , correct class is:  4\n",
      "row  3 , classfier ONE prediction:  6 , classfier TWO prediction:  6 , classfier THREE prediction:  7 , correct class is:  7\n",
      "row  4 , classfier ONE prediction:  8 , classfier TWO prediction:  4 , classfier THREE prediction:  8 , correct class is:  10\n",
      "row  7 , classfier ONE prediction:  8 , classfier TWO prediction:  7 , classfier THREE prediction:  8 , correct class is:  5\n",
      "row  8 , classfier ONE prediction:  7 , classfier TWO prediction:  8 , classfier THREE prediction:  6 , correct class is:  5\n",
      "row  9 , classfier ONE prediction:  7 , classfier TWO prediction:  8 , classfier THREE prediction:  8 , correct class is:  7\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if pred[i] == pred_1[i] and pred_1[i] == pred_2[i]:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"row \", i, \", classfier ONE prediction: \",str(pred[i])[2], \", classfier TWO prediction: \",str(pred_1[i])[2], \", classfier THREE prediction: \",str(pred_2[i])[2],\\\n",
    "              \", correct class is: \", y_test.iloc[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ensemble voting over the 3 classifier predictions we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following section is extracting all the predicitions from all of the 3 sklearn Multinomial Naive Bayes classifiers and average the result to correct error. From a statistical stand point, it is possible some correct answers will be wrongly corrected; however, the goal of the end result is to improve the exisitng classifier accuracy by implementing voting mechanism and bagging data when building the model. Also, by voting, we also close the distance between the prediction rating and the true rating even if we are not right on the rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = []\n",
    "for i in range(pred.shape[0]):\n",
    "    if pred[i] == pred_1[i] and pred_1[i] == pred_2[i]:\n",
    "        ensemble_pred.append(int(str(pred[i])[2]))\n",
    "    else:\n",
    "        temp_sum = int(str(pred[i])[2]) + int(str(pred_1[i])[2]) + int(str(pred_2[i])[2])\n",
    "        temp_pred = round(temp_sum/3)\n",
    "        ensemble_pred.append(temp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Brief debugg sector to make sure boolean checking goes through.\n",
    "print(ensemble_pred[1] == y_test.iloc[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(ensemble_pred)\n",
    "count = 0\n",
    "\n",
    "for i in range(total):\n",
    "    if ensemble_pred[i] == y_test.iloc[i][0]:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29399333333333333\n"
     ]
    }
   ],
   "source": [
    "new_accuracy = count / total\n",
    "print(new_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporant Note: \n",
    "#### because each time you run the model, it shuffles the entire data set before splitting, you sometimes see ensemble voting method being the slightly higher or slightly lesser than the sklearn Multinomial Naive Bayes classfiers, however, this matters not, because next section we will talk about average distance to the true rating which emsemble voting method almost always closes the gap statistically speaking, it would be an ultra rare conincidence that my method here does NOT close the gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see, our implementation in the above section works as expected. The point is, even though Naive Bayes classifier is already fairly accurate, but by writing our own ensemble method, it is possible to boost he accuracy a little bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution - Analysis and Experiment on Accuracy and Improved Prediction.\n",
    "## As we all know by now, the accuracy is constructed in such a way that if the true rating is 9 and even if we predicted a 8 or 10, it is considered wrong. Now, let's assume we have two classifiers, if both of them have the same accuracy, but one's prediction is averagely much more closer to the true rating, do we acknowledge that this predictor to be better? Of course, we do. The purpose here is to realize that accuracy as defined here is not the only measurement of which classifier is better, we should deploy more metrics to analyze the ensemble method and this section devotes to that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the average distance of classifier 1 prediction rating to the true rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = y_test.shape[0]\n",
    "total_distance = 0\n",
    "for i in range(total):\n",
    "    tmp_pred_rating = int(str(pred[i])[2])\n",
    "    tmp_true_rating = y_test.iloc[i][0]\n",
    "    if tmp_pred_rating != tmp_true_rating:\n",
    "        total_distance += abs(tmp_pred_rating - tmp_true_rating)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "average_distance_0 = total_distance / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance of the FIRST classfier prediction rating to the true rating:  1.3435666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Average distance of the FIRST classfier prediction rating to the true rating: \", average_distance_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the average distance of classifier 2 prediction rating to the true rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = y_test.shape[0]\n",
    "total_distance = 0\n",
    "for i in range(total):\n",
    "    tmp_pred_rating = int(str(pred_1[i])[2])\n",
    "    tmp_true_rating = y_test.iloc[i][0]\n",
    "    if tmp_pred_rating != tmp_true_rating:\n",
    "        total_distance += abs(tmp_pred_rating - tmp_true_rating)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "average_distance_1 = total_distance / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance of the SECOND classfier prediction rating to the true rating:  1.3413933333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Average distance of the SECOND classfier prediction rating to the true rating: \", average_distance_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the average distance of classifier 3 prediction rating to the true rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = y_test.shape[0]\n",
    "total_distance = 0\n",
    "for i in range(total):\n",
    "    tmp_pred_rating = int(str(pred_2[i])[2])\n",
    "    tmp_true_rating = y_test.iloc[i][0]\n",
    "    if tmp_pred_rating != tmp_true_rating:\n",
    "        total_distance += abs(tmp_pred_rating - tmp_true_rating)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "average_distance_2 = total_distance / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance of the THRID classfier prediction rating to the true rating:  1.3401066666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Average distance of the THRID classfier prediction rating to the true rating: \", average_distance_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the average distance of my own ensemble voting prediction rating to the true rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = y_test.shape[0]\n",
    "total_distance = 0\n",
    "for i in range(total):\n",
    "    tmp_pred_rating = ensemble_pred[i]\n",
    "    tmp_true_rating = y_test.iloc[i][0]\n",
    "    if tmp_pred_rating != tmp_true_rating:\n",
    "        total_distance += abs(tmp_pred_rating - tmp_true_rating)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "average_distance_ensemble = total_distance / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance of my ensemble classfier prediction rating to the true rating:  1.2847133333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Average distance of my ensemble classfier prediction rating to the true rating: \", average_distance_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph of the Average Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [1, 2, 3, 4]\n",
    "y = [average_distance_0, average_distance_1, average_distance_2, average_distance_ensemble]\n",
    "labels = [\"NB1\", \"NB2\", \"NB3\", \"My Ensemble\"] \n",
    "plt.bar(x, y, tick_label = labels, width = 0.7, color = [\"blue\"]) \n",
    "plt.xlabel(\"Name of the classfiers\") \n",
    "plt.ylabel(\"Average Distance\") \n",
    "plt.title(\"Average Distance to the True Rating\") \n",
    "plt.ylim(1.0, 1.3)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see above, all three Naive Bayes classfiers have very similar average distance to the true rating and my ensemble voting classfier yeild smaller average distance. My point here is, even if the accuracy of my classfier is exactly the same as the sklearn one, we should use my classfier because my average distance to the true rating is smaller by quite a few percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution - New way of defining accuracy incorporating distance measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upon till now, we understand that the emsemble voting technique yields lesser average distance to the true rating and I would like to factor this idea into my accuracy calcuation because it would reflect a more truthfully the reality that ensemble voting is indeed worth to use on top of existing methods. Hence, I would consider the prediction accurate if it lands within 1 rating distance to the true rating which is completely reasonable. If you think about a comment stated \"this is a great game\", how much less accurate am I if I rate it as 9 instead of the true rating 10? Not much, negligible fair to say. Therefore, I will go on and recaculate my result in such way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing an Auxiliary Function for our Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_accuracy(pred, y_test):\n",
    "    total = pred.shape[0]\n",
    "    count = 0\n",
    "    for i in range(total):\n",
    "        temp_pred = int(str(pred[i])[2])\n",
    "        temp_y = y_test.iloc[i][0]\n",
    "        if temp_pred == temp_y or abs(temp_pred - temp_y) <= 1:\n",
    "            count += 1\n",
    "            \n",
    "    return count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Accuracy for classfier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6559333333333334"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_accuracy(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Accuracy for classfier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590933333333333"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_accuracy(pred_1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Accuracy for classfier 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66062"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_accuracy(pred_2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Accuracy for my Ensemble Voting Clissfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6690733333333333\n"
     ]
    }
   ],
   "source": [
    "total = len(ensemble_pred)\n",
    "count = 0\n",
    "\n",
    "for i in range(total):\n",
    "    if ensemble_pred[i] == y_test.iloc[i][0] or abs(ensemble_pred[i] - y_test.iloc[i][0]) <= 1:\n",
    "        count += 1\n",
    "\n",
    "new_accuracy = count / total\n",
    "print(new_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with the consideration of the distance into the measurement, almost every time, the ensemble voting classfier beats the sklearn one but a few percents which I consider my way ensemble implementation and understanding to be reasonable at this point in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution - Finish up building my Ensemble Classfier\n",
    "## This section is to design my ensemble voting classfier and make sure outside intput is predicted when enter through text box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_voting_predict(comment):\n",
    "    input_np = np.array([[comment]])\n",
    "    input_df = pd.DataFrame(data=input_np, columns=[\"comment\"])\n",
    "    input_vector_0 = vectorizer.transform(input_df[\"comment\"])\n",
    "    input_vector_1 = vectorizer_1.transform(input_df[\"comment\"])\n",
    "    input_vector_2 = vectorizer_2.transform(input_df[\"comment\"])\n",
    "    pred_0 = Naive_Bayes_Multinomial.predict(input_vector_0)\n",
    "    pred_1 = Naive_Bayes_Multinomial_1.predict(input_vector_1)\n",
    "    pred_2 = Naive_Bayes_Multinomial_2.predict(input_vector_2)\n",
    "    \n",
    "#     print(pred_0, pred_1, pred_2)\n",
    "\n",
    "    rating_0 = int(str(pred_0[0])[2])\n",
    "    if int(str(pred_0[0])[2]) == 1 and str(pred_0[0])[3] == '0':\n",
    "        rating_0 = 10\n",
    "        \n",
    "    rating_1 = int(str(pred_1[0])[2])\n",
    "    if int(str(pred_1[0])[2]) == 1 and str(pred_1[0])[3] == '0':\n",
    "        rating_1 = 10\n",
    "        \n",
    "    rating_2 = int(str(pred_2[0])[2])\n",
    "    if int(str(pred_2[0])[2]) == 1 and str(pred_2[0])[3] == '0':\n",
    "        rating_2 = 10\n",
    "        \n",
    "    final_rating = (rating_0 + rating_1 + rating_2) / 3\n",
    "    \n",
    "    return round(final_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution - Wraping Everything in to my Own Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following section is my finalized EnsembleVoting class which will take x_train, y_train, x_test, y_test in numpy format, a percentage of the portion of the entire data you want to use and the number of Naive Bayes classfiers as need with which my class will split the data accordingly to do the bagging before training them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleVoting:\n",
    "    # x_train, y_train, x_test, and y_test are all\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, use_percentage=1, num_of_classifier=3):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.num_of_classifier = num_of_classifier\n",
    "        self.upper_index = math.ceil(x_train.shape[0] * use_percentage)\n",
    "        self.increment = math.ceil(self.upper_index / num_of_classifier)\n",
    "        self.x_df_container = []\n",
    "        self.y_df_container = []\n",
    "        self.vectorizers = self.instantiate_vectorizers()\n",
    "        self.naive_bayes = self.instantiate_naive_bayes()\n",
    "    \n",
    "    def fit_all_naive_bayes(self):\n",
    "        for i in range(self.num_of_classifier):\n",
    "            train_vector = self.vectorizers[i].fit_transform(self.x_df_container[i][\"comment\"])\n",
    "            target_train_vector = np.asarray(self.y_df_container[i][\"rating\"], dtype=\"|S6\")\n",
    "            self.naive_bayes[i].fit(train_vector, target_train_vector)\n",
    "    \n",
    "    def instantiate_naive_bayes(self):\n",
    "        naive_bayes = []\n",
    "        for i in range(self.num_of_classifier):\n",
    "            t_naive_bayes = NB()\n",
    "            naive_bayes.append(t_naive_bayes)\n",
    "        \n",
    "        return naive_bayes\n",
    "    \n",
    "    def instantiate_vectorizers(self):\n",
    "        vectorizers = []\n",
    "        for i in range(self.num_of_classifier):\n",
    "            t_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "            vectorizers.append(t_vectorizer)\n",
    "        \n",
    "        return vectorizers\n",
    "        \n",
    "    def groom_data(self):\n",
    "        split_indices = [0]\n",
    "        current_index = 0\n",
    "        while(True):\n",
    "            current_index += self.increment\n",
    "            if current_index <= self.upper_index:\n",
    "                split_indices.append(current_index)\n",
    "            else:\n",
    "                split_indices.append(self.upper_index)\n",
    "                break;\n",
    "                \n",
    "        for i in range(len(split_indices)-1):\n",
    "            l = i\n",
    "            r = i + 1\n",
    "            t_x_train, t_y_train = self.x_train[split_indices[l]:split_indices[r], :], self.y_train[split_indices[l]:split_indices[r], :]\n",
    "            t_x_train, t_y_train = pd.DataFrame(data=t_x_train, columns=[\"comment\"]), pd.DataFrame(data=t_y_train, columns=[\"rating\"])\n",
    "            self.x_df_container.append(t_x_train)\n",
    "            self.y_df_container.append(t_y_train)\n",
    "    \n",
    "    def ensemble_voting_predict(self, comment):\n",
    "        input_np = np.array([[comment]])\n",
    "        input_df = pd.DataFrame(data=input_np, columns=[\"comment\"])\n",
    "        ratings = []\n",
    "        \n",
    "        for i in range(self.num_of_classifier):\n",
    "            t_input_vector = self.vectorizers[i].transform(input_df[\"comment\"])\n",
    "            t_pred = self.naive_bayes[i].predict(t_input_vector)\n",
    "            rating = int(str(t_pred[0])[2])\n",
    "            \n",
    "            if int(str(t_pred[0])[2]) == 1 and str(t_pred[0])[3] == '0':\n",
    "                rating = 10\n",
    "            \n",
    "            ratings.append(rating)\n",
    "            \n",
    "        return round(sum(ratings) / len(ratings))\n",
    "        \n",
    "    \n",
    "    # Here is my effort to attempt to convert this into webapp(extra credit), have to clear all data first, and then serialize it and then just use the trained\n",
    "    # classifiers for the app program as there is size requirement from PythonAnyWhere\n",
    "    def clear_data_set(self):\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test = None, None, None, None\n",
    "        self.x_df_container, self.y_df_container = None, None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate my class, groom the input data, and fit all the naive bayes classifiers in my ensemblevoting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV = EnsembleVoting(x_train, y_train, x_test, y_test, use_percentage=1)\n",
    "EV.groom_data()\n",
    "EV.fit_all_naive_bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is not in Kaggle, this is a step in serialization for the webapp after everything is trained.\n",
    "EV.clear_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is not in Kaggle, this is a step in serialization for the webapp after everything is trained.\n",
    "# import pickle\n",
    "# with open('EV.txt', 'wb') as fh:\n",
    "#     pickle.dump(EV, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# if __name__ == \"__main__\":\n",
    "#     joblib.dump(EV, 'EV.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting my demonstration comments before doing the actual demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "2\n",
      "2\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(EV.ensemble_voting_predict(\"this game is so wonderful, the best game i have ever played.\"))\n",
    "print(EV.ensemble_voting_predict(\"nightmare, extremely unbalanced, the worst game, very poorly designed.\"))\n",
    "print(EV.ensemble_voting_predict(\"utterly pointless\"))\n",
    "print(EV.ensemble_voting_predict(\"average game\"))\n",
    "print(EV.ensemble_voting_predict(\"outstanding, great, golden game.\"))\n",
    "print(EV.ensemble_voting_predict(\"another horrible thriftstore pickup\"))\n",
    "print(EV.ensemble_voting_predict(\"dismal dice feast\"))\n",
    "print(EV.ensemble_voting_predict(\"hot pile of garbage\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution - Demonstration Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will try my hardest to use serialization to achieve the transition from local host to webapp, but in case the extra credit attempt doesn't work out, here is my demonstration interface for my EnsembleVoting class. UPDATE: After spending 12 hours of debugging, I finally am able to deploy my classfier to make prediction live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b7f38f35ea4b4590c1b83bba796f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9043603ff7e24f739995e0ce11ade429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', disabled=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e24761ad574b5a972f8c0a268e5673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict Rating', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4357d092de5544c9931ed505ae5c3f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Clear Entry', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_field = widgets.Text()\n",
    "display(input_field)\n",
    "output_field = widgets.Text(disabled=True)\n",
    "display(output_field)\n",
    "predict_button = widgets.Button(description=\"Predict Rating\")\n",
    "display(predict_button)\n",
    "clear_button = widgets.Button(description=\"Clear Entry\")\n",
    "display(clear_button)\n",
    "\n",
    "\n",
    "\n",
    "def handle_enter(sender):\n",
    "    rating = EV.ensemble_voting_predict(input_field.value)\n",
    "    output_field.value = str(rating)\n",
    "\n",
    "def handle_clear(v):\n",
    "    input_field.value = ''\n",
    "    output_field = ''\n",
    "\n",
    "input_field.on_submit(handle_enter)\n",
    "predict_button.on_click(handle_enter)\n",
    "clear_button.on_click(handle_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Challenges\n",
    "## Truth be told, I have spent weeks of work on this project. From brainstorming ideas on how to do this project, incrementally refining the data, trying out different methods before deciding on implementing ensemble voting mechanism to better the sklearn Naive Bayes classifier to finally writing everything and also making sure I give the extra mile of effort by implementing extra credit portion of the requirement which is Flask Web App deployment with my own class of ensemble voting classifer to make the prediction live. I have learned a tremendous amount of knowledge through this project and I truely feel that I am very comfortable with Kaggle/Jupyter Notebook. Aside from the time consuming aspect of this endeavor, I find deployment portion very hard and I will talk a little about how I overcame the difficulty. First of all, the data set is 1 GB and the upper limit of AnywherePython is only 100MB, therefore, there is no way we can preporcess and cut the size down to that amount. Even if we can, doing the training on each run of the Webapp would be utterly pointless. I then thought about the Python pickle module which I can use to serialize my EnsembleVoting classfier object after training and clearing all the data reference. After that, I spent hours on understanding how Flask works with Python and HTML. Then, I finished my Flask APP writing; however, when I was about to deployed it, there was an extremely subtle differenct between serializing using Juypter Notebook and using just Python file which makes the former not work with the deployment. To debug this portion, I spent almost 10 hours to do my research and I finally find that serilization only works if my class is defined in another file, otherwise, \"__main__\" will be attached to my byte code when I make the store. Finally, I am able to overcome all these chanllenge and finish this term project. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
    "2. http://www.kaiteli.io/Kaite%20Li_1001645704_Practice.html (This is my own work for Kaggle practice)\n",
    "3. https://www.kaggle.com/c/spooky-author-identification/discussion/42289\n",
    "4. https://stackoverflow.com/questions/49153253/pandas-rounding-when-converting-float-to-integer\n",
    "5. https://cmdlinetips.com/2018/02/how-to-subset-pandas-dataframe-based-on-values-of-a-column/\n",
    "6. https://stackoverflow.com/questions/45333530/pandas-drop-columns\n",
    "7. https://towardsdatascience.com/5-minute-guide-to-plotting-with-pandas-e8c0f40a1df4\n",
    "8. https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "9. https://www.geeksforgeeks.org/getting-frequency-counts-of-a-columns-in-pandas-dataframe/\n",
    "10. https://medium.com/@contactsunny/how-to-split-your-dataset-to-train-and-test-datasets-using-scikit-learn-e7cf6eb5e0d\n",
    "11. https://www.geeksforgeeks.org/graph-plotting-in-python-set-1/\n",
    "12. https://intellipaat.com/community/5638/removing-non-english-words-from-text-using-python\n",
    "13. https://blog.dominodatalab.com/interactive-dashboards-in-jupyter/\n",
    "14. https://www.kaggle.com/shahules/basic-eda-cleaning-and-glove#Data-Cleaning\n",
    "15. https://stackoverflow.com/questions/11585793/are-numpy-arrays-passed-by-reference\n",
    "16. https://flask.palletsprojects.com/en/0.12.x/quickstart/#rendering-templates\n",
    "17. https://www.youtube.com/watch?v=IIi6e5oDZ68\n",
    "18. https://www.stefaanlippens.net/python-pickling-and-dealing-with-attributeerror-module-object-has-no-attribute-thing.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
